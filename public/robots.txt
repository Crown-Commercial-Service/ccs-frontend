# www.robotstxt.org/
#    .__________________________.
#    | .___________________. |==|
#    | | ................. | |  |
#    | | ::[ Dear robot ]: | |  |
#    | | ::::[ be nice ]:: | |  |
#    | | ::::::::::::::::: | |  |
#    | | ::::::::::::::::: | |  |
#    | | ::::::::::::::::: | |  |
#    | | ::::::::::::::::: | | ,|
#    | !___________________! |(c|
#    !_______________________!__!
#   /                            \
#  /  [][][][][][][][][][][][][]  \
# /  [][][][][][][][][][][][][][]  \
#(  [][][][][____________][][][][]  )
# \ ------------------------------ /
#  \______________________________/

# Allow crawling of all content
User-agent: *
Disallow: *?all==*
Disallow: *?statuses%5B%5D=*
Disallow: *&statuses%5B%5D=*
Disallow: *?statuses=*
Disallow: *&statuses=*

Disallow: *?search=*
Disallow: *&search=*
Disallow: *?framework=*
Disallow: *&framework=*
Disallow: *?lot-filter-nested=*
Disallow: *&lot-filter-nested=*
Disallow: *?limit=*
Disallow: *&limit=*

Disallow: *?categories=*
Disallow: *&categories=*
Disallow: *?sectors=*
Disallow: *&sectors=*
Disallow: *?products_services=*
Disallow: *&products_services=*